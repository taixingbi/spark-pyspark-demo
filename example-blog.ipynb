{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/trustyou-engineering/topic-modelling-with-pyspark-and-spark-nlp-a99d063f1a6e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ip-10-0-0-213.ec2.internal:4042\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.4</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[4]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Spark NLP</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fd47a88b0f0>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Spark NLP\")\\\n",
    "    .master(\"local[4]\")\\\n",
    "    .config(\"spark.driver.memory\",\"16G\")\\\n",
    "    .config(\"spark.driver.maxResultSize\", \"0\") \\\n",
    "    .config(\"spark.jars.packages\", \"com.johnsnowlabs.nlp:spark-nlp_2.11:2.6.3\")\\\n",
    "    .config(\"spark.kryoserializer.buffer.max\", \"1000M\")\\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[reviewText: string]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "path = 'data/Musical_instruments_reviews.csv'\n",
    "data = spark.read.csv(path, header=True)\n",
    "text_col = 'reviewText'\n",
    "review_text = data.select(text_col).filter(F.col(text_col).isNotNull())\n",
    "review_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|          reviewText|\n",
      "+--------------------+\n",
      "|    that's just like|\n",
      "|The product does ...|\n",
      "|The primary job o...|\n",
      "|Nice windscreen p...|\n",
      "|This pop filter i...|\n",
      "|So good that I bo...|\n",
      "|I have used monst...|\n",
      "|I now use this ca...|\n",
      "|Perfect for my Ep...|\n",
      "|Monster makes the...|\n",
      "|Monster makes a w...|\n",
      "|I got it to have ...|\n",
      "|If you are not us...|\n",
      "|I love it, I used...|\n",
      "|I bought this to ...|\n",
      "|I bought this to ...|\n",
      "|This Fender cable...|\n",
      "|wanted it just on...|\n",
      "|I've been using t...|\n",
      "|Fender cords look...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.select(text_col).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DocumentAssembler_fd4a738ba700"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sparknlp.base import DocumentAssembler\n",
    "documentAssembler = DocumentAssembler().setInputCol(text_col).setOutputCol('document')\n",
    "documentAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tokenizer_44fbea5a4aef"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sparknlp.annotator import Tokenizer\n",
    "tokenizer = Tokenizer() \\\n",
    "     .setInputCols(['document']) \\\n",
    "     .setOutputCol('tokenized')\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sparknlp.annotator import Normalizer\n",
    "normalizer = Normalizer() \\\n",
    "     .setInputCols(['tokenized']) \\\n",
    "     .setOutputCol('normalized') \\\n",
    "     .setLowercase(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lemma_antbnc download started this may take some time.\n",
      "Approximate size to download 907.6 KB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "from sparknlp.annotator import LemmatizerModel\n",
    "lemmatizer = LemmatizerModel.pretrained() \\\n",
    "     .setInputCols(['normalized']) \\\n",
    "     .setOutputCol('lemmatized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "eng_stopwords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StopWordsCleaner_b0209b9bee71"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sparknlp.annotator import StopWordsCleaner\n",
    "stopwords_cleaner = StopWordsCleaner() \\\n",
    "     .setInputCols(['lemmatized']) \\\n",
    "     .setOutputCol('no_stop_lemmatized') \\\n",
    "     .setStopWords(eng_stopwords)\n",
    "\n",
    "stopwords_cleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos_anc download started this may take some time.\n",
      "Approximate size to download 4.3 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "from sparknlp.annotator import PerceptronModel\n",
    "pos_tagger = PerceptronModel.pretrained('pos_anc') \\\n",
    "     .setInputCols(['document', 'lemmatized']) \\\n",
    "     .setOutputCol('pos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chunker_20016ff25b6d"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sparknlp.annotator import Chunker\n",
    "allowed_tags = ['<JJ>+<NN>', '<NN>+<NN>']\n",
    "chunker = Chunker() \\\n",
    "     .setInputCols(['document', 'pos']) \\\n",
    "     .setOutputCol('ngrams') \\\n",
    "     .setRegexParsers(allowed_tags)\n",
    "chunker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Finisher_ea2eaf2d963a"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sparknlp.base import Finisher\n",
    "# finisher = Finisher().setInputCols(['unigrams', 'ngrams'])\n",
    "finisher = Finisher().setInputCols(['ngrams'])\n",
    "finisher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline_a2cbc3446c94"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "pipeline = Pipeline() \\\n",
    "     .setStages([documentAssembler,\n",
    "                 tokenizer,\n",
    "                 normalizer,\n",
    "                 lemmatizer,\n",
    "                 stopwords_cleaner,\n",
    "                 pos_tagger,\n",
    "                 chunker,\n",
    "                 finisher])\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[reviewText: string, finished_ngrams: array<string>]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_review = pipeline.fit(review_text).transform(review_text)\n",
    "processed_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[reviewText: string, finished_ngrams: array<string>, final: array<string>]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import concat\n",
    "processed_review = processed_review.withColumn('final',\n",
    "     concat(\n",
    "#          F.col('finished_unigrams'), \n",
    "            F.col('finished_ngrams')))\n",
    "processed_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+\n",
      "|          reviewText|     finished_ngrams|               final|\n",
      "+--------------------+--------------------+--------------------+\n",
      "|    that's just like|                  []|                  []|\n",
      "|The product does ...|[double screened,...|[double screened,...|\n",
      "|The primary job o...|[primary job, not...|[primary job, not...|\n",
      "|Nice windscreen p...|[Nice windscreen,...|[Nice windscreen,...|\n",
      "|This pop filter i...|[pop filter, stud...|[pop filter, stud...|\n",
      "|So good that I bo...|[heavy cord, last...|[heavy cord, last...|\n",
      "|I have used monst...|[good reason, Sim...|[good reason, Sim...|\n",
      "|I now use this ca...|[pedal board, hig...|[pedal board, hig...|\n",
      "|Perfect for my Ep...|[Epiphone Sherato...|[Epiphone Sherato...|\n",
      "|Monster makes the...|[best cables, Mon...|[best cables, Mon...|\n",
      "|Monster makes a w...|[wide array, high...|[wide array, high...|\n",
      "|I got it to have ...|                  []|                  []|\n",
      "|If you are not us...|[large sustaining...|[large sustaining...|\n",
      "|I love it, I used...|        [Yamaha ypt]|        [Yamaha ypt]|\n",
      "|I bought this to ...|[home studio, mid...|[home studio, mid...|\n",
      "|I bought this to ...|[other options, d...|[other options, d...|\n",
      "|This Fender cable...|[perfect length, ...|[perfect length, ...|\n",
      "|wanted it just on...|[nice looking, gr...|[nice looking, gr...|\n",
      "|I've been using t...|[indestructable g...|[indestructable g...|\n",
      "|Fender cords look...|[Fender cords loo...|[Fender cords loo...|\n",
      "+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "processed_review.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
